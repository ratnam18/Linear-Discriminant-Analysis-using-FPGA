# Linear-Discriminant-Analysis-using-FPGA
Linear discriminant analysis (LDA), normal discriminant analysis (NDA), or discriminant function analysis is a generalization of Fisher's linear discriminant, a method used in statistics, pattern recognition, and machine learning to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a linear classifier, or, more commonly, for dimensionality reduction before later classification.
Here, in this project LDA is applied on 32x32 binary image to classify image into to binary classes(0 and 1). The code for LDA is written in Matlab, where every function is written manually i.e. mean, covariance, standard deviation, calculating eigen values, eigen vectors etc. We compared our user defined functions efficiency with in-built Matlab functions, and output for LDA was approximately equal. After this the use of in-built HDL coder helped to create hardware compatible code for LDA. This code was more than 2500+ lines and very complex to understand.
SO, we decided to create our own verilog files for all the functions used in LDA. We used Xillinc software to write HDL scripts. After this we tested the HDL code on hardware FPGA to compute LDA of the binary image. The results were same as the results generated by Matlab.
